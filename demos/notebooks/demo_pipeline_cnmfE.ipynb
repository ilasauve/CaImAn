{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"content-type\"><style type=\"text/css\">ol</style></head><body class=\"c5\"><p class=\"c0 c4\"><span class=\"c3\"></span></p><p class=\"c2 title\" id=\"h.rrbabt268i6e\"><h1>CaImAn&rsquo;s Demo pipeline</h1></p><p class=\"c0\"><span class=\"c3\">This notebook will help to demonstrate the process of CaImAn and how it uses different functions to denoise, deconvolve and demix neurons from a Calcium Imaging Video. </span></p>\n",
    "<p><img src=\"../../docs/img/quickintro.png\" /></p>\n",
    "<p class=\"c0\"><span class=\"c3\">More information can be found in CaImAn&rsquo;s documentation. </span></p>\n",
    "</html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "try:\n",
    "    get_ipython().magic(u'load_ext autoreload')\n",
    "    get_ipython().magic(u'autoreload 2')\n",
    "    get_ipython().magic(u'matplotlib qt')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(format=\n",
    "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
    "                    # filename=\"/tmp/caiman.log\",\n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.source_extraction import cnmf\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import inspect_correlation_pnr\n",
    "from caiman.components_evaluation import estimate_components_quality_auto\n",
    "from caiman.motion_correction import motion_correct_oneP_rigid, motion_correct_oneP_nonrigid\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "import cv2\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "import bokeh.plotting as bpl\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some parameters\n",
    "few of them (that typically shouldn't be changed for 1p data) will be set directly calling the CNMF object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "fnames = ['data_endoscope.tif']  # filename to be processed\n",
    "frate = 10                       # movie frame rate\n",
    "decay_time = 0.4                 # length of a typical transient in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion correction parameters\n",
    "do_motion_correction_nonrigid = True\n",
    "do_motion_correction_rigid = False  # in this case it will also save a rigid motion corrected movie\n",
    "gSig_filt = (3, 3)       # size of filter, in general gSig (see below),\n",
    "#                          change this one if algorithm does not work\n",
    "max_shifts = (5, 5)      # maximum allowed rigid shift\n",
    "splits_rig = 10          # for parallelization split the movies in  num_splits chuncks across time\n",
    "strides = (48, 48)       # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)      # overlap between pathes (size of patch strides+overlaps)\n",
    "splits_els = 10          # for parallelization split the movies in  num_splits chuncks across time\n",
    "#                          (remember that it should hold that length_movie/num_splits_to_process_rig>100)\n",
    "upsample_factor_grid = 4 # upsample factor to avoid smearing when merging patches\n",
    "max_deviation_rigid = 3  # maximum deviation allowed for patch with respect to rigid shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for source extraction and deconvolution\n",
    "p = 1               # order of the autoregressive system\n",
    "K = None            # upper bound on number of components per patch, in general None\n",
    "gSig = 3            # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
    "gSiz = 13           # average diameter of a neuron, in general 4*gSig+1\n",
    "merge_thresh = .7   # merging threshold, max correlation allowed\n",
    "rf = 40             # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "stride_cnmf = 20    # amount of overlap between the patches in pixels\n",
    "#                     (keep it at least large as gSiz, i.e 4 times the neuron size gSig)\n",
    "tsub = 2            # downsampling factor in time for initialization,\n",
    "#                     increase if you have memory problems\n",
    "ssub = 1            # downsampling factor in space for initialization,\n",
    "#                     increase if you have memory problems\n",
    "Ain = None          # if you want to initialize with some preselected components\n",
    "#                     you can pass them here as boolean vectors\n",
    "low_rank_background = None  # None leaves background of each patch intact,\n",
    "#                             True performs global low-rank approximation \n",
    "gnb = -1            # number of background components (rank) if positive,\n",
    "#                     else exact ring model with following settings\n",
    "#                         gnb=-2: Return background as b and W\n",
    "#                         gnb=-1: Return full rank background B\n",
    "#                         gnb= 0: Don't return background\n",
    "nb_patch = -1       # number of background components (rank) per patch,\n",
    "#                     use 0 or -1 for exact background of ring model (cf. gnb)\n",
    "min_corr = .8       # min peak value from correlation image\n",
    "min_pnr = 10        # min peak to noise ration from PNR image\n",
    "ssub_B = 2          # additional downsampling factor in space for background\n",
    "ring_size_factor = 1.4  # radius of ring is gSiz*ring_size_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for component evaluation\n",
    "min_SNR = 3            # adaptive way to set threshold on the transient size\n",
    "r_values_min = 0.85    # threshold on space consistency (if you lower more components\n",
    "#                        will be accepted, potentially with worst quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset if not already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fnames = [download_demo(fnames[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Re)start cluster.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cm.stop_server(dview=dview) # stop it if it was running\n",
    "except:\n",
    "    pass\n",
    "\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(backend='local', # use this one\n",
    "                                                 n_processes=24,  # number of process to use, if you go out of memory try to reduce this one\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of a memory mappable file. \n",
    "    - Performs motion correction and simultaneously creates a memory mappable file in F order\n",
    "    - Transforms into C order (much more efficient for parallel processing\n",
    "    - If you have multiple files there are ways to process many at the same time (not shown)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_motion_correction_nonrigid or do_motion_correction_rigid:\n",
    "    # do motion correction rigid\n",
    "    mc = motion_correct_oneP_rigid(fnames,\n",
    "                                   gSig_filt=gSig_filt,\n",
    "                                   max_shifts=max_shifts,\n",
    "                                   dview=dview,\n",
    "                                   splits_rig=splits_rig,\n",
    "                                   save_movie=not(do_motion_correction_nonrigid)\n",
    "                                   )\n",
    "\n",
    "    new_templ = mc.total_template_rig\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.subplot(1,2,1)    \n",
    "    plt.title('Filtered template')\n",
    "    plt.imshow(new_templ)       #% plot template\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Estimated shifts')\n",
    "    plt.plot(mc.shifts_rig)     #% plot rigid shifts\n",
    "    plt.legend(['x shifts', 'y shifts'])\n",
    "    plt.xlabel('frames')\n",
    "    plt.ylabel('pixels')\n",
    "    \n",
    "    bord_px = np.ceil(np.max(np.abs(mc.shifts_rig))).astype(np.int)     #borders to eliminate from movie because of motion correction        \n",
    "\n",
    "    # do motion correction nonrigid\n",
    "    if do_motion_correction_nonrigid:\n",
    "        mc = motion_correct_oneP_nonrigid(\n",
    "            fnames,\n",
    "            gSig_filt=gSig_filt,\n",
    "            max_shifts=max_shifts,\n",
    "            strides=strides,\n",
    "            overlaps=overlaps,\n",
    "            splits_els=splits_els,\n",
    "            upsample_factor_grid=upsample_factor_grid,\n",
    "            max_deviation_rigid=max_deviation_rigid,\n",
    "            dview=dview,\n",
    "            splits_rig=None,\n",
    "            save_movie=True,  # whether to save movie in memory mapped format\n",
    "            new_templ=new_templ  # template to initialize motion correction\n",
    "        )\n",
    "\n",
    "        bord_px = np.ceil(\n",
    "            np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
    "                       np.max(np.abs(mc.y_shifts_els)))).astype(np.int)\n",
    "\n",
    "    # create memory mappable file in the right order on the hard drive (C order)        \n",
    "        fname_new = cm.save_memmap([mc.fname_tot_els], base_name='memmap_',\n",
    "                                   order = 'C', border_to_0=bord_px, dview=dview)\n",
    "    else:\n",
    "        fname_new = cm.save_memmap([mc.fname_tot_rig], base_name='memmap_',\n",
    "                                   order = 'C', border_to_0=bord_px, dview=dview)\n",
    "else:\n",
    "    fname_new = cm.save_memmap(fnames, base_name='memmap_', order = 'C')\n",
    "\n",
    "# load memory mappable file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "Y = Yr.T.reshape((T,) + dims, order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the movie (optional). This will require loading the movie in memory which in general is not needed by the pipeline. Displaying the movie uses the OpenCV library. Press `q` to close the video panel. **BEWARE** the movie may appear in the background!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_orig = cm.movie(Y)\n",
    "downsample_ratio = 1.\n",
    "offset_mov = -np.min(m_orig[:100])  # make the dataset mostly non-negative\n",
    "m_orig.resize(1, 1, downsample_ratio).play(gain=2, offset=offset_mov, fr=30, magnification=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect summary images and set parameters\n",
    "Check the optimal values of min_corr and min_pnr by moving slider in the figure that pops up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute some summary images (correlation and peak to noise)\n",
    "cn_filter, pnr = cm.summary_images.correlation_pnr(Y, gSig=gSig, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n",
    "# inspect the summary images and set the parameters\n",
    "inspect_correlation_pnr(cn_filter, pnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print parameters set above, modify them if necessary based on summary images\n",
    "print(min_corr) # min correlation of peak (from correlation image)\n",
    "print(min_pnr)  # min peak to noise ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set CNMF parameters and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm = cnmf.CNMF(n_processes=n_processes,\n",
    "                method_init='corr_pnr',             # use this for 1 photon\n",
    "                k=K,\n",
    "                gSig=(gSig, gSig),\n",
    "                gSiz=(gSiz, gSiz),\n",
    "                merge_thresh=merge_thresh,\n",
    "                p=p,\n",
    "                dview=dview,\n",
    "                tsub=tsub,\n",
    "                ssub=ssub,\n",
    "                Ain=Ain,\n",
    "                rf=rf,\n",
    "                stride=stride_cnmf,\n",
    "                only_init_patch=True,               # just leave it as is\n",
    "                gnb=gnb,\n",
    "                nb_patch=nb_patch,\n",
    "                method_deconvolution='oasis',       # could use 'cvxpy' alternatively\n",
    "                low_rank_background=low_rank_background,\n",
    "                update_background_components=True,  # sometimes setting to False improve the results\n",
    "                min_corr=min_corr,\n",
    "                min_pnr=min_pnr,\n",
    "                normalize_init=False,               # just leave as is\n",
    "                center_psf=True,                    # leave as is for 1 photon\n",
    "                ssub_B=ssub_B,\n",
    "                ring_size_factor=ring_size_factor,\n",
    "                del_duplicates=True,                # whether to remove duplicates from initialization\n",
    "                border_pix=bord_px)                 # number of pixels to not consider in the borders\n",
    "cnm.fit(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot contours of identified components against correlation image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd = cm.utils.visualization.plot_contours(cnm.A, cn_filter, thr=.8, vmax=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier\n",
    "\n",
    "<img src=\"../../docs/img/evaluationcomponent.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "idx_components, idx_components_bad, comp_SNR, r_values, pred_CNN = estimate_components_quality_auto(\n",
    "                            Y, cnm.A, cnm.C, cnm.b, cnm.f, cnm.YrA, frate, \n",
    "                            decay_time, gSig, dims, dview=dview, \n",
    "                            min_SNR=min_SNR, r_values_min=r_values_min, use_cnn=False)\n",
    "\n",
    "print(' ***** ')\n",
    "print((len(cnm.C)))\n",
    "print((len(idx_components)))\n",
    "print(r_values[idx_components_bad])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot contours of selected and rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOT COMPONENTS\n",
    "\n",
    "plt.figure(figsize=(15,8));\n",
    "plt.subplot(121);\n",
    "crd = cm.utils.visualization.plot_contours(cnm.A.tocsc()[:,idx_components], cn_filter, thr=.8, vmax=0.95)\n",
    "plt.title('Contour plots of accepted components')\n",
    "plt.subplot(122); \n",
    "crd = cm.utils.visualization.plot_contours(cnm.A.tocsc()[:,idx_components_bad], cn_filter, thr=.8, vmax=0.95)\n",
    "plt.title('Contour plots of rejected components');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using:\n",
    "'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted components\n",
    "nb_view_patches(Yr, cnm.A.tocsc()[:, idx_components], cnm.C[idx_components], \n",
    "                cnm.b, cnm.f, dims[0], dims[1], YrA=cnm.YrA[idx_components], image_neurons=cn_filter,\n",
    "                denoised_color='red', thr=0.8, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected components\n",
    "nb_view_patches(Yr, cnm.A.tocsc()[:, idx_components_bad], cnm.C[idx_components_bad], \n",
    "                cnm.b, cnm.f, dims[0], dims[1], YrA=cnm.YrA[idx_components_bad], image_neurons=cn_filter,\n",
    "                denoised_color='red', thr=0.8, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.stop_server(dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some instructive movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = cnm.b.dot(cnm.f)\n",
    "if 'sparse' in str(type(B)):\n",
    "    B = B.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% denoised movie\n",
    "cm.movie(np.reshape(cnm.A.tocsc()[:,idx_components].dot(cnm.C[idx_components])+B,dims+(-1,), order = 'F').transpose(2,0,1)).play(magnification=3, gain = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% only neurons\n",
    "cm.movie(np.reshape(cnm.A.tocsc()[:,idx_components].dot(cnm.C[idx_components]),dims+(-1,), order = 'F').transpose(2,0,1)).play(magnification=3, gain = 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% only the background\n",
    "cm.movie(np.reshape(B,dims+(-1,), order = 'F').transpose(2,0,1)).play(magnification=3, gain = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% residuals\n",
    "cm.movie(np.array(Y)-np.reshape(cnm.A.tocsc()[:,:].dot(cnm.C[:])+B,dims+(-1,), order = 'F').transpose(2,0,1)).play(magnification=3, gain = 10., fr = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% eventually, you can rerun the algorithm on the residuals\n",
    "plt.imshow(cm.movie(np.array(Y)-np.reshape(cnm.A.tocsc()[:,:].dot(cnm.C[:])+B,dims+(-1,), order = 'F').transpose(2,0,1)).local_correlations(swap_dim=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
